<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Quay.io Documentation</title>

  <link href="https://coreos.com/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link href="https://coreos.com/assets/css/docs.css" rel="stylesheet">
  <link href="https://coreos.com/assets/css/pygments-manni.css" rel="stylesheet">

  <link href="https://coreos.com/assets/css/coreos.css" rel="stylesheet">

  <link href="https://coreos.com/assets/css/syntax-highlight.css" rel="stylesheet">

  <link href="/stylesheets/docs.css" rel="stylesheet">

<!--[if lt IE 9]>
  <script src="https://coreos.com/assets/js/html5shiv.js"></script>
  <script src="https://coreos.com/assets/js/respond.min.js"></script>
  <![endif]-->

  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,400italic,600,700,900" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600,700" rel="stylesheet" type="text/css">

  <link href="https://coreos.com/assets/css/gh-fork-ribbon.css" rel="stylesheet">
<!--[if IE]>
      <link rel="stylesheet" href="https://coreos.com/assets/css/gh-fork-ribbon.ie.css" />
<![endif]-->

  <script src="https://coreos.com/assets/js/jquery.js"></script>

  <style type="text/css">
  </style>
</head>

<body data-spy="scroll" data-target=".coreos-docs-sidebar" class="co-m-main-nav-full">
  <div class="navbar navbar-static-top co-m-main-nav-container" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".coreos-nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" id="quay-logo" href="https://quay.io" target=""></a>
      </div>
      <div class="navbar-collapse collapse coreos-nav-collapse">
        <ul class="nav navbar-nav">
         <li><a href="/">Community Documentation</a></li>
          <li><a href="/solution">Articles and Solutions</a></li>
          <li><a href="/guides">Guides</a></li>
          <li><a href="/glossary">Glossary</a></li>
          <li><a href="https://quay.io/contact">Support</a></li>
        </ul>
      </div>
    </div>
  </div>
  <div class="github-fork-ribbon-wrapper right fixed">
    <div class="github-fork-ribbon">
      <a href="https://github.com/coreos/quay-docs/blob/gh-pages/solution/repeatable-deployments.html">Fork me on GitHub</a>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-lg-9 col-md-9 col-sm-12">
        <div class="coreos-docs">
          <h1>Repeatable and Testable Deployments</h1>
          <h3 id="the-perils-of-deployment">The perils of deployment</h3>

<p>Deploying to production: words that for many developers can chill their hearts to the core. Even with extensive testing and today’s scriptable deployment systems (Chef, Puppet, etc), deployment to production machines can still result in cryptic errors, odd behaviors and lots of inventive swearing. All this stress and headache stems from one primary issue: Production environments rarely, if ever, replicate staging or development environments completely. Unit tests are run on development machines or in continuous integration systems; integration tests are run on staging machines or by hand. These different environments try to replicate production as closely as possible, but even the slightest difference can result in disaster. Differences in libraries, file layouts, even minor revisions of the operating system, can result in unexpected behavior and downtime. We once had a production push breakage (in our previous product) as a result of <em>the method used to link a dependency</em>. Even though we had matched the versions of the library and the operating system exactly, we still encountered problems.</p>

<p>Fortunately, we discovered that Docker can come to the rescue, solving not only the environment problem, but helping to grant us further peace of mind by properly testing our deployments before they go to production.</p>

<p>This article will discuss how to setup Docker for <em>reproducible</em>, <em>tested</em> deployments. If you need background on the terms used in this article, please read our article <a href="https://medium.com/devops-programming/7f5fd023158f">What is Docker?</a> first.</p>

<h3 id="being-environmentally-friendly">Being environmentally friendly</h3>

<p>The first major benefit of using Docker for deployment is its ability to reproduce a specific environment, quickly and on demand. A Docker container represents a sandbox of sorts, one in which a developer can finely control all dependencies of their software, including operating system version, library installation and supporting files. As a result, any software running inside the Docker container is guaranteed to be running under the same environment, whether on a developer’s machine, staging or production:</p>

<p>The reproducibility of the Docker container provides a level of comfort that current script-based deployment systems simply cannot match. A developer can develop a new version of a service on their machine, test it locally or on staging and then push the <strong>same image</strong> to production with the understanding that the testing environment <strong>is</strong> the production environment under which their code will now be running.</p>

<div class="article-image"><img src="image00.png"></div>

<h3 id="preparing-a-docker-image">Preparing a Docker image</h3>

<p>Preparing images to run in Docker can be done in one of two ways: by manually building layers or via a Dockerfile, which allows for reproducible construction of images. Since reproducibility is the goal of our production deployments, we will write a Dockerfile that represents our production code and its dependencies. For this article, we’ll set up a simple web server that writes “Hello World”. The source code for the web server and its associated Dockerfile can be found <a href="https://github.com/DevTable/rtdexample">here</a>.</p>

<p>At its core, a Dockerfile is a simple list of commands building on top of a <em>base image</em>, with each command forming a new layer in the Docker image. The base image of a Docker image is extremely important: It defines the flavour of Linux used, and which tools are by available by default to the code running inside the container. At Quay.io, we recommend the <a href="https://github.com/phusion/baseimage-docker">phusion/baseimage</a>, which runs a version of Ubuntu specially modified to run inside a Docker container.</p>

<p>To get started, we create a file named <code>Dockerfile</code> in the directory containing our existing code. The first line of a Dockerfile is, typically, the <code>FROM</code> command, which indicates the base image we are using (in this case, Phusion base). The Phusion base image can be found on the public Docker index at phusion/baseimage, so we place that directly in the FROM line:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="k">FROM</span> phusion/baseimage:0.9.9
</code></pre></div>
<p>The <code>:0.9.9</code> above specifies that we are requesting that specific <em>tag</em> of the <code>baseimage</code> repository. Without a specific tag, the <code>latest</code> tag would always be used; any update to the <code>baseimage</code> repository could get pulled by our Dockerfile at any time, leading to possible breakages.</p>

<p>Once we have specified the base image, it is customary to add a <code>MAINTAINER</code> command. This &quot;command&quot; (which has no effects) indicates the author of the Dockerfile:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="k">FROM</span> phusion/baseimage:0.9.9
<span class="k">MAINTAINER</span> John Smith &lt;john.smith@example.com&gt;
</code></pre></div>
<h3 id="working-in-a-good-environment">Working in a good ENVironment</h3>

<p>In order to use the Phusion base image we just setup, we need to tell it a home directory for our root user, as well as the fact that (under normal circumstances), the Docker image will not be running with an interactive terminal. Docker allows environment variables to be set using the <code>ENV</code> command, so we add two environment variables to our context;</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="k">ENV</span> DEBIAN_FRONTEND noninteractive
<span class="k">ENV</span> HOME /root
</code></pre></div>
<h3 id="all-your-base-are-belong-to-this">All your base are belong to this</h3>

<p>Now that we have the base image setup, our next step is to start adding the dependencies upon which our service will rely. Dockerfile’s provide a number of commands for adding dependencies; this article will cover the three or four most important commands needed for setting up the environment for our web service.</p>

<p>Our <a href="https://github.com/DevTable/rtdexample">web service</a> is a Python application, which depends on <a href="https://pypi.python.org/pypi">PyPI</a> to manage its own libraries. We therefore start by installing Python and PyPI:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># Install Ubuntu packages.</span>
<span class="c"># New packages should be added as their own apt-get install lines below the existing install commands.</span>
<span class="k">RUN</span> apt-get update
<span class="k">RUN</span> apt-get install -y python-dev
<span class="k">RUN</span> apt-get install -y python-pip
</code></pre></div>
<p>The <code>RUN</code> command in a Dockerfile will run any command given, under the context and file system of the Docker container, and produce a new image layer with any resulting file system changes. We first run <code>apt-get update</code> to make sure our package manager is up to date. Then, in different calls, we ask our package manager to install both python and pip. The <code>-y</code> flag skips interactive confirmation.</p>

<p>As an aside: Why do we run each of the <code>apt-get -y install</code> commands on their own? The answer lies in how Docker handles <em>caching</em>. When building a Dockerfile, Docker will first check its own image cache to see if any of the layers previously built exist. If so, the build step will be skipped and the previous layer used. By placing each install command on its own, if we ever need to add or remove a package, we can do so without having to &quot;reinstall&quot; every other package used inside the Dockerfile, saving potentially large amounts of build time.</p>

<p>Once we’ve installed all the Ubuntu packages necessary to run our service, we conduct a bit of cleanup. This is not strictly necessary, but it does mean that the resulting Docker image is cleaner:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># Clean up any files used by apt-get</span>
<span class="k">RUN</span> apt-get clean <span class="p">&amp;</span>amp<span class="p">;&amp;</span>amp<span class="p">;</span> rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
</code></pre></div>
<p>Our next step is to have PyPI install all the required libraries and packages necessary for our Python application. To do so, we’ll use the <code>pip install -r requirements.txt</code> convention, which installs all packages specified in a <code>requirements.txt</code> file.</p>

<p>The problem is…how are we going to get our <code>requirements.txt</code> file into the proper directory? The answer: using the <code>ADD</code> command.</p>

<h3 id="adding-dependencies">ADDing dependencies</h3>

<p>The <code>ADD</code> command specifies that a file, located at the input path, should be copied from the same directory as the Dockerfile to the output path inside the container. For example, an <code>ADD</code> command like:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="k">ADD</span> config/somefile.txt myapp/anotherfile.txt
</code></pre></div>
<p>will copy the file located at <code>config/somefile.txt</code> (relative to the Dockerfile’s directory) to <code>myapp/anotherfile.txt</code> relative to the working directory inside the container.</p>

<p>Therefore, for our purposes, it is simple to add our <code>requirements.txt</code> and install it. Note that we also call <code>WORKDIR</code> to ensure that all our commands are run inside the <code>/root</code> folder:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># Change our working directory to /root</span>
<span class="k">WORKDIR</span> /root

<span class="c"># Copy over our requirements.txt</span>
<span class="k">ADD</span> requirements.txt /root/requirements.txt

<span class="c"># Install our Python dependencies.</span>
<span class="k">RUN</span> pip install -r requirements.txt
</code></pre></div>
<h3 id="asset-management">Asset management</h3>

<p>As we’ve seen, the <code>ADD</code> command can be used to add external files into the Docker image. Once we’ve installed our Python dependencies, our next step is to <code>ADD</code> any assets (including the web service’s code), to the Dockerfile. This can be done in steps or by copying entire directories:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># Copy over code and static assets.</span>
<span class="k">ADD</span> static /root/static
<span class="k">ADD</span> application.py /root/application.py
</code></pre></div>
<p>A question might be raised at this point: Why not copy all the static assets along with <code>requirements.txt</code> in the earlier part of the Dockerfile? The answer, once again, has to do with <em>caching</em>. The Dockerfile caching system will invalidate <em>all</em> steps after <em>any</em> <code>ADD</code> command that has a file that has changed, since it has been called. In our Dockerfile example, if we placed <code>ADD static /root/static</code> <em>before</em> the <code>pip install -r requirements.txt</code> call, then any time we changed a static asset file, the entire PyPI installation process would be called again. Since that is obviously not the behavior we’d like, you should try to <em>place dependencies as late as possible when ordering these commands</em>.</p>

<h3 id="running-your-service">Running your service</h3>

<p>The final step in setting up a service via a Dockerfile is to have said Dockerfile invoke the service when the image is run. Since we are using the Phusion Base Image, we can take advantage of its embedded init service to run our application. To do so, we copy a shell script into the services directory. The shell script will be automatically run and started when the container first starts:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># Add my runservice.sh shell script as a service and make sure it has the proper flags</span>
<span class="k">ADD</span> runservice.sh /etc/service/mywebserver/run
<span class="k">RUN</span> chmod +x /etc/service/mywebserver/run
</code></pre></div>
<p>Our final task is to tell Docker that we are exposing ports for our web service, and to call the init service described above. The <code>EXPOSE</code> command indicates to Docker the ports that should be exposed by the container when run and the <code>CMD</code> command tells Docker the command to run when the container is started:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># Tell Docker that we are exposing the HTTP ports</span>
<span class="k">EXPOSE</span> <span class="m">443</span> <span class="m">80</span>

<span class="c"># Finally, tell Docker to run the init service.</span>
<span class="k">CMD</span> <span class="o">[</span><span class="s2">&quot;/sbin/my_init&quot;</span><span class="o">]</span>
</code></pre></div>
<p>We are now done our Dockerfile and can discuss different ways to build it.</p>

<h3 id="building-and-deploying-our-new-image">Building and deploying our new image</h3>

<p>Building a Dockerfile into an image is quite simple. In the directory that contains the Dockerfile and its data files (requirements.txt, static, etc), one simply executes:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">$ docker build -t quay.io/mynamespace/myreponame .
</code></pre></div>
<p>The command above tells Docker to <em>build</em> the Dockerfile and data found in the current directory and, if sucessful, to <em>tag</em> it as the repository named <em>quay.io/mynamespace/myreponame.</em></p>

<p>At this point you&#39;ll need an <a href="https://quay.io/signin">Quay.io account</a> to make further progress.</p>

<p>Once our build has been successful, we can then <em>push</em> our created image to Quay.io:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">$ docker push quay.io/mynamespace/myreponame
</code></pre></div>
<p>and on our production server, <em>pull</em> and <em>run</em> it:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">$ docker run quay.io/mynamespace/myreponame -d
</code></pre></div>
<p>The <code>-d</code> flag tells Docker to run the image in detached (background) mode, rather than waiting until the container exits to return the prompt.</p>

<h3 id="tested-deployments">Tested deployments</h3>

<p>As we can see, it is a fairly simple and straightforward process to use a Dockerfile and <code>docker build</code> to create a reproducible runtime environment for our server, including all its dependencies, libraries and static assets. This is a very useful solution to a large portion of the deployment issues we discussed above, but it still leaves much to be desired; even if we have a test suite running on our code at all times, we still cannot be sure that our code runs the same under our test environment as our production environment.</p>

<p>Unit tests are the obvious solution; they can help to identify problems in our production image before we push it, and verify that it at least (partially) functions the way we intend. Since Docker allows us to run any command during the build process, we can take advantage of this fact to run our unit tests <em>while building the image</em>. If our tests succeed, we have some confidence that the runtime environment for our service is valid; if they fail, then the build fails, and we will have not created a potentially bad production image.</p>

<p>Running tests as part of the build process is quite easy; we simply execute a <code>RUN</code> command with our test runner. For example, since we are writing a Python web service, here is the testing command we’ll add to our Dockerfile:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="k">RUN</span> python -m unittest discover
</code></pre></div>
<p>The above command will discover and run any unit tests found in our Python source code. To that end, we also need to make sure to <code>ADD</code> our unit tests to the assets inside our image:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="k">ADD</span> <span class="nb">test</span> /root/test
</code></pre></div>
<p>Finally, we should delete any test files once our unit tests run. We do so to ensure that our production code cannot rely (accidentally or on purpose) on our test code:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="k">RUN</span> rm -rf <span class="nb">test</span>
</code></pre></div>
<p>Altogether, this results in the following being added to the Dockerfile:</p>
<div class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile"><span class="c"># Add my runservice.sh shell script as a service and make sure it has the proper flags</span>
<span class="k">ADD</span> runservice.sh /etc/service/mywebserver/run
<span class="k">RUN</span> chmod +x /etc/service/mywebserver/run

<span class="c"># Test our production image.</span>
<span class="k">ADD</span> <span class="nb">test</span> /root/test
<span class="k">RUN</span> python -m unittest discover
<span class="k">RUN</span> rm -rf <span class="nb">test</span>

<span class="c"># Tell Docker that we are exposing the HTTP ports</span>
<span class="k">EXPOSE</span> <span class="m">443</span> <span class="m">80</span>

<span class="c"># Finally, tell Docker to run the init service.</span>
<span class="k">CMD</span> <span class="o">[</span><span class="s2">&quot;/sbin/my_init&quot;</span><span class="o">]</span>
</code></pre></div>
<p>Every time we build our image, it’ll be fully tested as part of the build process, resulting in a <em>tested</em>, <em>reproducible</em> production environment!</p>

<h3 id="automating-this-process">Automating this process</h3>

<p>While the above build process is very simple and straightforward, it suffers from one major downside: it requires a developer or devops engineer to rebuild the image before every production push. Recognizing this problem, Quay.io has <a href="http://blog.devtable.com/2014/03/link-your-quayio/repositories-to-github.html">built support for automatically building Dockerfiles on pushes to any Github repository</a>. To setup, go to the Admin Panel for your Quay.io repository and create a new &quot;Github repository trigger&quot; under the &quot;Build Triggers&quot; tab. Once authenticated and setup, any time a developer pushes to your Github repository, Quay.io will pickup the changes, conduct the Dockerfile build and, if successful, push the new image to your repository. If the build fails for whatever reason (including test failures), results can be viewed in the build history.</p>

<p>As an example, we’ve created a repository in Quay.io that builds the Dockerfile and service contained in this article, which you can view <a href="https://quay.io/repository/quay/rtdeample">here</a>.</p>

<p>We think that Docker and Dockerfiles provide a unique ability for both developers and devops engineers to be more confident in their production deployment. When used with Quay.io’s automatic build systems, engineers can be confident that code is both tested and ready for deployment as soon as possible. <a href="https://quay.io">Try Quay.io today!</a></p>

        </div>
      </div>
      <div class="coreos-docs-sidebar col-lg-3 col-md-3 col-sm-12 hidden-xs">
        <ul class="nav coreos-docs-sidenav"></ul>
      </div>
    </div>
  </div>

  <script src="https://coreos.com/dist/js/bootstrap.min.js"></script>
  <script src="https://coreos.com/assets/js/holder.js"></script>
  <script src="https://coreos.com/assets/js/application.js"></script>
  <script src="https://coreos.com/assets/js/masonry.pkgd.min.js"></script>

  <script src="https://coreos.com/assets/js/jquery-ui-1.9.1.custom.min.js"></script>
  <script src="https://coreos.com/assets/js/jquery.tocify.js"></script>

  <script type="text/javascript">
  $(document).ready(function() {
    $('[data-toggle=tooltip]').tooltip();
  });
  </script>
  <script src="https://coreos.com/assets/js/docs.js"></script>
  <script type="text/javascript" src="https://coreos.com/assets/js/events.js"></script>
</body>
</html>
